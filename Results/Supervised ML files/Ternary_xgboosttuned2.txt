CLASSIFICATION: kmeans3 
 
 # CV training metrics: per fold 
eXtreme Gradient Boosting 

377 samples
 20 predictor
  3 classes: 'Low', 'Moderate', 'High' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 10 times) 
Summary of sample sizes: 302, 301, 302, 302, 301, 303, ... 
Addtional sampling using up-sampling

Resampling results across tuning parameters:

  eta    nrounds  logLoss     AUC        prAUC      Accuracy   Kappa      Mean_F1    Mean_Sensitivity  Mean_Specificity  Mean_Pos_Pred_Value
  0.001   50      1.06426353  0.9971216  0.8521900  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.001  100      1.03157246  0.9971791  0.8646771  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.001  300      0.91530191  0.9969953  0.8892697  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.001  500      0.81656813  0.9968880  0.8988770  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.005   50      0.94283149  0.9968525  0.8595520  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.005  100      0.81513523  0.9968413  0.8896646  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.005  300      0.48619650  0.9965986  0.9159336  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.005  500      0.30585701  0.9965289  0.9237678  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.010   50      0.81480784  0.9970560  0.8776605  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.010  100      0.62373134  0.9971223  0.9004411  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.010  300      0.24521418  0.9966959  0.9233749  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.010  500      0.11234263  0.9967284  0.9274834  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.050   50      0.30447283  0.9967676  0.9153461  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.050  100      0.11064206  0.9967312  0.9252828  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.050  300      0.03092710  0.9973478  0.9389340  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.050  500      0.02899040  0.9991217  0.9438185  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.100   50      0.11175772  0.9966066  0.9263739  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.100  100      0.03692923  0.9967588  0.9297085  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.100  300      0.02877443  0.9990424  0.9398359  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.100  500      0.02801708  0.9992507  0.9411060  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.200   50      0.03725158  0.9969197  0.9305603  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.200  100      0.02969964  0.9984759  0.9380832  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.200  300      0.02778807  0.9992245  0.9414147  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  0.200  500      0.02751353  0.9991665  0.9414669  0.9954875  0.9925538  0.9945969  0.994234          0.9976683         0.9955016          
  Mean_Neg_Pred_Value  Mean_Precision  Mean_Recall  Mean_Detection_Rate  Mean_Balanced_Accuracy
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             
  0.9976178            0.9955016       0.994234     0.3318292            0.9959512             

Tuning parameter 'max_depth' was held constant at a value of 1
Tuning parameter 'gamma' was held constant at a value of 0
Tuning parameter
 'colsample_bytree' was held constant at a value of 0.6
Tuning parameter 'min_child_weight' was held constant at a value of 1
Tuning parameter 'subsample'
 was held constant at a value of 1
Mean_Balanced_Accuracy was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 1, eta = 0.001, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 1.

 # CV training metrics: overall and per class 
Confusion Matrix and Statistics

          Reference
Prediction  Low Moderate High
  Low       534        2    0
  Moderate    6     1418    9
  High        0        0 1801

Overall Statistics
                                          
               Accuracy : 0.9955          
                 95% CI : (0.9928, 0.9974)
    No Information Rate : 0.4801          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9926          
                                          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: Low Class: Moderate Class: High
Sensitivity              0.9889          0.9986      0.9950
Specificity              0.9994          0.9936      1.0000
Pos Pred Value           0.9963          0.9895      1.0000
Neg Pred Value           0.9981          0.9991      0.9954
Precision                0.9963          0.9895      1.0000
Recall                   0.9889          0.9986      0.9950
F1                       0.9926          0.9940      0.9975
Prevalence               0.1432          0.3767      0.4801
Detection Rate           0.1416          0.3761      0.4777
Detection Prevalence     0.1422          0.3801      0.4777
Balanced Accuracy        0.9941          0.9961      0.9975

 # CV training macro-metrics 
               F1 Balanced Accuracy               AUC 
        0.9947047         0.9959176         0.9971000 

 # Best hyperparameter results 
  nrounds max_depth   eta gamma colsample_bytree min_child_weight subsample Mean_Balanced_Accuracy Mean_Balanced_AccuracySD       AUC       AUCSD
1      50         1 0.001     0              0.6                1         1              0.9959512              0.009795813 0.9971216 0.005231572
