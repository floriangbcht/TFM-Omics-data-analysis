CLASSIFICATION: kmeans_GMM2 
 
 # CV training metrics: per fold 
eXtreme Gradient Boosting 

377 samples
 20 predictor
  2 classes: 'LowToMod', 'ModToHigh' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 10 times) 
Summary of sample sizes: 301, 302, 301, 303, 301, 301, ... 
Addtional sampling using up-sampling

Resampling results across tuning parameters:

  gamma  logLoss    AUC  prAUC      Accuracy   Kappa      F1         Sensitivity  Specificity  Pos_Pred_Value  Neg_Pred_Value  Precision  Recall  Detection_Rate
  0.0    0.6624098  1    0.7521152  1.0000000  1.0000000  1.0000000  1            1.0000000    1.0000000       1               1.0000000  1       0.167083      
  0.1    0.6630042  1    0.7272459  1.0000000  1.0000000  1.0000000  1            1.0000000    1.0000000       1               1.0000000  1       0.167083      
  0.2    0.6626510  1    0.7414258  1.0000000  1.0000000  1.0000000  1            1.0000000    1.0000000       1               1.0000000  1       0.167083      
  0.4    0.6625857  1    0.7239900  1.0000000  1.0000000  1.0000000  1            1.0000000    1.0000000       1               1.0000000  1       0.167083      
  0.6    0.6624799  1    0.7521385  1.0000000  1.0000000  1.0000000  1            1.0000000    1.0000000       1               1.0000000  1       0.167083      
  0.8    0.6625638  1    0.7287180  0.9997333  0.9990403  0.9992000  1            0.9996825    0.9984615       1               0.9984615  1       0.167083      
  1.0    0.6630680  1    0.7065907  0.9994667  0.9981372  0.9984593  1            0.9993600    0.9970330       1               0.9970330  1       0.167083      
  Balanced_Accuracy
  1.0000000        
  1.0000000        
  1.0000000        
  1.0000000        
  1.0000000        
  0.9998413        
  0.9996800        

Tuning parameter 'nrounds' was held constant at a value of 50
Tuning parameter 'max_depth' was held constant at a value of 1
Tuning parameter 'eta' was
 held constant at a value of 0.001
Tuning parameter 'colsample_bytree' was held constant at a value of 0.6
Tuning parameter 'min_child_weight' was held
 constant at a value of 1
Tuning parameter 'subsample' was held constant at a value of 0.6
Balanced_Accuracy was used to select the optimal model using the largest value.
The final values used for the model were nrounds = 50, max_depth = 1, eta = 0.001, gamma = 0, colsample_bytree = 0.6, min_child_weight = 1 and subsample = 0.6.

 # CV training metrics: overall and per class 
Confusion Matrix and Statistics

           Reference
Prediction  LowToMod ModToHigh
  LowToMod       630         0
  ModToHigh        0      3140
                                    
               Accuracy : 1         
                 95% CI : (0.999, 1)
    No Information Rate : 0.8329    
    P-Value [Acc > NIR] : < 2.2e-16 
                                    
                  Kappa : 1         
                                    
 Mcnemar's Test P-Value : NA        
                                    
            Sensitivity : 1.0000    
            Specificity : 1.0000    
         Pos Pred Value : 1.0000    
         Neg Pred Value : 1.0000    
              Precision : 1.0000    
                 Recall : 1.0000    
                     F1 : 1.0000    
             Prevalence : 0.1671    
         Detection Rate : 0.1671    
   Detection Prevalence : 0.1671    
      Balanced Accuracy : 1.0000    
                                    
       'Positive' Class : LowToMod  
                                    

 # CV training macro-metrics 
               F1 Balanced Accuracy               AUC 
                1                 1                 1 

 # Best hyperparameter results 
  nrounds max_depth   eta gamma colsample_bytree min_child_weight subsample Balanced_Accuracy Balanced_AccuracySD AUC AUCSD
1      50         1 0.001     0              0.6                1       0.6                 1                   0   1     0
